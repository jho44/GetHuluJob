{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7f7db8-418c-41f9-9f11-2912575b219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Turing, Turing.RandomMeasures\n",
    "using Plots, StatsPlots\n",
    "using Statistics, Random, LinearAlgebra\n",
    "using MCMCChains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11017e9d-e0a3-415e-9c01-536637e11cef",
   "metadata": {},
   "source": [
    "Define the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1843b87-a91e-4339-975d-45933eb56554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LDA (generic function with 4 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function LDA(w, K, D)\n",
    "    # K: number of topics\n",
    "    # D: number of words\n",
    "    # M = number of documents\n",
    "    # this gets the length of the 1st dimension of array w\n",
    "    M = size(w, 1)\n",
    "    # N = number of words per document\n",
    "    # length of the 2nd dimension of w\n",
    "    N = size(w, 2)\n",
    "\n",
    "    # topic distributions\n",
    "    # A Vector of Vectors, size M, each initialized to undef\n",
    "    # Each inner vector will have K entries that add up to 1.\n",
    "    θ = Vector{Vector}(undef, M)\n",
    "    α = 1.0\n",
    "    for m = 1:M\n",
    "        θ[m] ~ Dirichlet(K, α)\n",
    "    end\n",
    "    # println(\"theta:\")\n",
    "    # println(θ)\n",
    "\n",
    "    # word distributions (for each topic)\n",
    "    ψ = Vector{Vector}(undef, K)\n",
    "    η = 0.01\n",
    "    for k = 1:K\n",
    "        ψ[k] ~ Dirichlet(D, η)\n",
    "    end\n",
    "\n",
    "    # println(\"ψ (word distributions for each topic):\")\n",
    "    # println(ψ)\n",
    "\n",
    "    # one entry in outer vec per doc\n",
    "    # the ints represent the topic assignment of each word\n",
    "    z = Vector{Vector{Int}}(undef, M)\n",
    "\n",
    "    for m = 1:M\n",
    "        # in each doc, initialize each word's topic as 0 (I think)\n",
    "        z[m] = zeros(Int, N)\n",
    "        for n = 1:N\n",
    "            # select topic for word n in document m\n",
    "            # draw from the topic distribution for that doc\n",
    "            z[m][n] ~ Categorical(θ[m])\n",
    "            # select symbol for word n in document m from topic z[m][n]\n",
    "            # draw from the word distribution for that topic\n",
    "            w[m,n] ~ Categorical(ψ[z[m][n]])\n",
    "        end\n",
    "    end\n",
    "    # println(\"z:\")\n",
    "    # println(z)\n",
    "    # println(\"w:\")\n",
    "    # println(w)\n",
    "    return w\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9520155c-86e6-459c-ba66-f2c7923d63d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of docs\n",
    "M = 2\n",
    "# number words per doc\n",
    "N = 10\n",
    "# number of topics\n",
    "K = 4\n",
    "# number of words in corpus\n",
    "D = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d7ccd-5a8e-43ae-af88-bc11eb8cb719",
   "metadata": {},
   "source": [
    "TODO: Import the data. It should be an M x N matrix, where each entry is an int representing a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48faf94e-0bce-454a-b101-0a0e3636cc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×10 Matrix{Int64}:\n",
       "  1  2  3  1   2  9  1   2  3  1\n",
       " 12  3  4  5  12  3  4  15  2  3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_data = [1 2 3 1 2 9 1 2 3 1; 12 3 4 5 12 3 4 15 2 3]\n",
    "condition_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd427e-1c12-4325-b72d-19de71282836",
   "metadata": {},
   "source": [
    "Condition the model with the provided documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f6577f-9560-4d9c-90af-732d90dd85ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicPPL.Model{typeof(LDA), (:w, :K, :D), (), (), Tuple{Matrix{Int64}, Int64, Int64}, Tuple{}, DynamicPPL.DefaultContext}(LDA, (w = [1 2 … 3 1; 12 3 … 2 3], K = 4, D = 20), NamedTuple(), DynamicPPL.DefaultContext())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditioned_LDA = LDA(condition_data, K, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16968df9-11a9-4369-b3ab-3adacf29470b",
   "metadata": {},
   "source": [
    "Sample the model. It currently uses a Sequential Monte Carlo (SMC) sampler, but it can also be configured to use importance sampling (IS), Metropolis Hastings (MH), or Particle Gibbs (PG). It can also combine multiple samplers so one is used for the discrete variables and a different one is used for the continuous variables, such as Hamiltonian Markov Chain (HMC) or the No U-Turn Sampler (NUTS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42aab129-97b1-4223-8739-02fc31dea4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chains MCMC chain (1000×110×1 Array{Float64, 3}):\n",
       "\n",
       "Log evidence      = -179.75136502367724\n",
       "Iterations        = 1:1:1000\n",
       "Number of chains  = 1\n",
       "Samples per chain = 1000\n",
       "Wall duration     = 5.94 seconds\n",
       "Compute duration  = 5.94 seconds\n",
       "parameters        = θ[1][1], θ[1][2], θ[1][3], θ[1][4], θ[2][1], θ[2][2], θ[2][3], θ[2][4], ψ[1][1], ψ[1][2], ψ[1][3], ψ[1][4], ψ[1][5], ψ[1][6], ψ[1][7], ψ[1][8], ψ[1][9], ψ[1][10], ψ[1][11], ψ[1][12], ψ[1][13], ψ[1][14], ψ[1][15], ψ[1][16], ψ[1][17], ψ[1][18], ψ[1][19], ψ[1][20], ψ[2][1], ψ[2][2], ψ[2][3], ψ[2][4], ψ[2][5], ψ[2][6], ψ[2][7], ψ[2][8], ψ[2][9], ψ[2][10], ψ[2][11], ψ[2][12], ψ[2][13], ψ[2][14], ψ[2][15], ψ[2][16], ψ[2][17], ψ[2][18], ψ[2][19], ψ[2][20], ψ[3][1], ψ[3][2], ψ[3][3], ψ[3][4], ψ[3][5], ψ[3][6], ψ[3][7], ψ[3][8], ψ[3][9], ψ[3][10], ψ[3][11], ψ[3][12], ψ[3][13], ψ[3][14], ψ[3][15], ψ[3][16], ψ[3][17], ψ[3][18], ψ[3][19], ψ[3][20], ψ[4][1], ψ[4][2], ψ[4][3], ψ[4][4], ψ[4][5], ψ[4][6], ψ[4][7], ψ[4][8], ψ[4][9], ψ[4][10], ψ[4][11], ψ[4][12], ψ[4][13], ψ[4][14], ψ[4][15], ψ[4][16], ψ[4][17], ψ[4][18], ψ[4][19], ψ[4][20], z[1][1], z[1][2], z[1][3], z[1][4], z[1][5], z[1][6], z[1][7], z[1][8], z[1][9], z[1][10], z[2][1], z[2][2], z[2][3], z[2][4], z[2][5], z[2][6], z[2][7], z[2][8], z[2][9], z[2][10]\n",
       "internals         = lp, weight\n",
       "\n",
       "Summary Statistics\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    mean \u001b[0m \u001b[1m     std \u001b[0m \u001b[1m naive_se \u001b[0m \u001b[1m    mcse \u001b[0m \u001b[1m     ess \u001b[0m \u001b[1m    rhat \u001b[0m \u001b[1m ess_per_sec \u001b[0m\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m     Float64 \u001b[0m\n",
       "\n",
       "     θ[1][1]    0.0930    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     θ[1][2]    0.5804    0.0000     0.0000    0.0000       NaN       NaN           NaN\n",
       "     θ[1][3]    0.0975    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     θ[1][4]    0.2291    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     θ[2][1]    0.1694    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     θ[2][2]    0.7406    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     θ[2][3]    0.0632    0.0000     0.0000    0.0000       NaN       NaN           NaN\n",
       "     θ[2][4]    0.0269    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][1]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][2]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][3]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][4]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][5]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][6]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][7]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][8]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "     ψ[1][9]    0.4932    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "    ψ[1][10]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "    ψ[1][11]    0.0000    0.0000     0.0000    0.0000    2.6720    0.9990        0.4495\n",
       "      ⋮           ⋮         ⋮         ⋮          ⋮         ⋮         ⋮           ⋮\n",
       "\u001b[36m                                                                          89 rows omitted\u001b[0m\n",
       "\n",
       "Quantiles\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    2.5% \u001b[0m \u001b[1m   25.0% \u001b[0m \u001b[1m   50.0% \u001b[0m \u001b[1m   75.0% \u001b[0m \u001b[1m   97.5% \u001b[0m\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\n",
       "\n",
       "     θ[1][1]    0.0930    0.0930    0.0930    0.0930    0.0930\n",
       "     θ[1][2]    0.5804    0.5804    0.5804    0.5804    0.5804\n",
       "     θ[1][3]    0.0975    0.0975    0.0975    0.0975    0.0975\n",
       "     θ[1][4]    0.2291    0.2291    0.2291    0.2291    0.2291\n",
       "     θ[2][1]    0.1694    0.1694    0.1694    0.1694    0.1694\n",
       "     θ[2][2]    0.7406    0.7406    0.7406    0.7406    0.7406\n",
       "     θ[2][3]    0.0632    0.0632    0.0632    0.0632    0.0632\n",
       "     θ[2][4]    0.0269    0.0269    0.0269    0.0269    0.0269\n",
       "     ψ[1][1]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "     ψ[1][2]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "     ψ[1][3]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "     ψ[1][4]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "     ψ[1][5]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "     ψ[1][6]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "     ψ[1][7]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "     ψ[1][8]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "     ψ[1][9]    0.4932    0.4932    0.4932    0.4932    0.4932\n",
       "    ψ[1][10]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "    ψ[1][11]    0.0000    0.0000    0.0000    0.0000    0.0000\n",
       "      ⋮           ⋮         ⋮         ⋮         ⋮         ⋮\n",
       "\u001b[36m                                                 89 rows omitted\u001b[0m\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_chain = sample(conditioned_LDA, SMC(), 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c900b49-075e-4389-bd69-8a34b6364c25",
   "metadata": {},
   "source": [
    "This represents the word distribution of each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2fae8e-8bf9-434d-8de2-890591781bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Vector{Float64}}:\n",
       " [8.339945352934453e-67, 1.6207337651679205e-6, 1.8417237966967173e-84, 6.839910920634829e-125, 1.147373085156585e-10, 7.0902000101806676e-43, 2.276688720631089e-9, 1.4622788041341917e-52, 0.4931699580797472, 2.409253584478786e-29, 9.758457185140399e-9, 3.4436617200581426e-86, 8.154700304200247e-22, 3.824201656689989e-46, 4.582575090813536e-14, 4.5263650236723275e-57, 1.1776059229366975e-63, 0.06513525946925518, 0.44169131488971214, 1.8346775919086609e-6]\n",
       " [0.9544412231845386, 5.697446433965199e-13, 1.0855917988602781e-14, 1.1307077064669073e-16, 2.5624065185083515e-65, 1.378185610179918e-133, 1.2147668870925905e-11, 1.1926722689074882e-18, 2.603744383525184e-17, 3.2618526668577096e-29, 1.2314821454624585e-7, 0.04555865365349639, 0.0, 7.321726490934666e-101, 1.0220123270515363e-12, 6.338887950081083e-34, 5.565970761555031e-35, 3.142418481910138e-36, 1.4309558167761946e-65, 4.302778977929825e-20]\n",
       " [1.802149674953276e-21, 3.229906076659316e-10, 0.3759128042467313, 3.9054539825910035e-78, 1.6650385907377002e-33, 2.4839421857986496e-9, 1.487290971464084e-38, 1.9137413253525098e-20, 2.986258867254771e-80, 2.8845384273397067e-25, 0.0013048066052610285, 2.288932587647708e-31, 0.0038829874756740814, 0.013563457643301836, 1.3940860490465616e-68, 4.218189757852901e-22, 5.382393158774568e-28, 0.6053359412211592, 9.389059921616498e-13, 8.143187994371768e-137]\n",
       " [0.9346557450139209, 0.06534425498504189, 2.575667104615025e-19, 2.52856897760731e-100, 2.633429956597959e-16, 1.738561484332469e-42, 9.116280783150934e-36, 3.3199924823192454e-216, 3.2874611810437425e-92, 5.8224547401852245e-115, 1.089291622411411e-25, 1.2271611060428316e-38, 2.9806474276838482e-58, 9.195529663850453e-79, 2.3287709957428047e-20, 3.9259395e-317, 3.093188419109222e-164, 4.528612802269734e-22, 8.561081374049308e-54, 1.0365666765396085e-12]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_dists = Vector{Vector{Float64}}(undef, K)\n",
    "for j = 1:K\n",
    "    topic_word_dists[j] = [mean(cond_chain, \"ψ[$j][$i]\") for i in 1:D]\n",
    "end\n",
    "topic_word_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39243f1-d27c-42f8-add5-dd0fa41c9968",
   "metadata": {},
   "source": [
    "Query the distribution of topics in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ca58c9-4511-4e51-85c5-456a48a93894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Vector{Float64}}:\n",
       " [0.09295633367114257, 0.5804187860456147, 0.09753235199927433, 0.22909252828396762]\n",
       " [0.1693518229234748, 0.7405616591578033, 0.06317470671035684, 0.026911811208365922]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_distributions = Vector{Vector{Float64}}(undef, M)\n",
    "for j = 1:M\n",
    "    document_topic_distributions[j] = [mean(cond_chain, \"θ[$j][$i]\") for i in 1:K]\n",
    "end\n",
    "document_topic_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296567e-f6aa-4d3a-bb3b-31f6a2f3f2be",
   "metadata": {},
   "source": [
    "Get the highest probability topic for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58f48a1a-9e99-493c-a5b2-110f79a2b52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Tuple{Int64, Float64}}:\n",
       " (2, 0.5804187860456147)\n",
       " (2, 0.7405616591578033)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_prob_topic_per_movie = Vector{Tuple{Int, Float64}}(undef, M)\n",
    "for doc = 1:M\n",
    "    max_prob = 0.0\n",
    "    max_ind = 0\n",
    "    for topic = 1:K\n",
    "        if document_topic_distributions[doc][topic] > max_prob\n",
    "            max_prob = document_topic_distributions[doc][topic]\n",
    "            max_ind = topic\n",
    "        end\n",
    "    end\n",
    "    highest_prob_topic_per_movie[doc] = (max_ind, max_prob) \n",
    "end\n",
    "highest_prob_topic_per_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101e63d-b4dc-445d-b7ef-c4b02e2ad41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
